{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a8aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import mannwhitneyu\n",
    "# !pip install cliffs_delta\n",
    "from cliffs_delta import cliffs_delta\n",
    "from scipy.stats import wilcoxon\n",
    "from numpy import median,mean\n",
    "from tqdm import tqdm\n",
    "import sqlite3,os,re\n",
    "from IPython.display import display\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d44c00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cate = {'Ac':'Accessibility',\n",
    "'Bl':'Blogging',\n",
    "'De':'Developer Tools',\n",
    "'Fu':'Fun',\n",
    "'Ne':'News & Weather',\n",
    "'Ph':'Photos',\n",
    "'Pr':'Productivity',\n",
    "'Se':'Search Tools',\n",
    "'Sh':'Shopping',\n",
    "'So':'Social & Communication',\n",
    "'Sp':'Sports'}\n",
    "extensions = {\n",
    "    #12\n",
    "'fmidkjgknpkbmninbmklhcgaalfalbdh':{'category':'Ac','label':0,'pp':1,'target':'Generic'},\n",
    "'ffnhmkgpdmkajhomnckhabkfeakhcamm':{'category':'Bl','label':0,'pp':1,'target':'Generic'},\n",
    "'gppongmhjkpfnbhagpmjfkannfbllamg':{'category':'De','label':0,'pp':1,'target':'Generic'},\n",
    "'iginnfkhmmfhlkagcmpgofnjhanpmklb':{'category':'Fu','label':0,'pp':1,'target':'Generic'},\n",
    "'kpghljlpdknmomchobaoecdlkcpocaga':{'category':'Ne','label':0,'pp':1,'target':'News'},\n",
    "'lamfengpphafgjdgacmmnpakdphmjlji':{'category':'Ph','label':0,'pp':1,'target':'Generic'},\n",
    "'gpdjojdkbbmdfjfahjcgigfpmkopogic':{'category':'Pr','label':0,'pp':1,'target':'Generic'},\n",
    "'bmhcbmnbenmcecpmpepghooflbehcack':{'category':'Se','label':0,'pp':1,'target':'Generic'},\n",
    "'pgmbeccjfkdbpdjfoldaahpfamjjafma':{'category':'Sh','label':0,'pp':1,'target':'Shoppingjp'},\n",
    "'cimpffimgeipdhnhjohpbehjkcdpjolg':{'category':'So','label':0,'pp':1,'target':'Video_youtube'},\n",
    "'ahcblhpcealjpkmndgmkdnebbjakicno':{'category':'Sp','label':0,'pp':1,'target':'Espn'},\n",
    "    'pgniedifoejifjkndekolimjeclnokkb':{'category':'Fu','label':0,'pp':1,'target':'Video_twitch'},\n",
    "    \n",
    "    #11\n",
    "'gmopgnhbhiniibbiilmbjilcmgaocokj':{'category':'Ac','label':1,'pp':2,'target':'Video_youtube'},\n",
    "'ffjnfifmelbmglnajefiipdeejghkkjg':{'category':'Bl','label':1,'pp':2,'target':'Generic'},\n",
    "'bkhaagjahfmjljalopjnoealnfndnagc':{'category':'De','label':1,'pp':2,'target':'GitHub'},\n",
    "'ikdgincnppajmpmnhfheflannaiapmlm':{'category':'Fu','label':1,'pp':2,'target':'Generic'},\n",
    "'kfimphpokifbjgmjflanmfeppcjimgah':{'category':'Ne','label':1,'pp':2,'target':'Generic'},\n",
    "'lcpkicdemehhmkjolekhlglljnkggfcf':{'category':'Ph','label':1,'pp':1,'target':'Generic'},\n",
    "'nngceckbapebfimnlniiiahkandclblb':{'category':'Pr','label':1,'pp':2,'target':'Generic'},\n",
    "'naankklphfojljboaokgfbheobbgenka':{'category':'Se','label':1,'pp':2,'target':'Generic'},\n",
    "'fhjanlpjlfhhbhbnjohflphmfccbhmoi':{'category':'Sh','label':1,'pp':2,'target':'Shoppingjp'},\n",
    "'bkkjeefjfjcfdfifddmkdmcpmaakmelp':{'category':'So','label':1,'pp':2,'target':'Video_youtube'},\n",
    "'lokmacldfjfgajcebibmmfohacnikhhd':{'category':'Sp','label':1,'pp':1,'target':'Draftkings'},\n",
    "    #13\n",
    "'alncdjedloppbablonallfbkeiknmkdi':{'category':'Ac','label':2,'pp':1,'target':'Generic'},\n",
    "'pkihbahhbihfoebgdfkibnblbhjfgefc':{'category':'Bl','label':2,'pp':1,'target':'Apk'},\n",
    "'dapjbgnjinbpoindlpdmhochffioedbn':{'category':'De','label':2,'pp':1,'target':'Generic'},\n",
    "'fadndhdgpmmaapbmfcknlfgcflmmmieb':{'category':'Fu','label':2,'pp':1,'target':'Video_twitch'},\n",
    "'iolcbmjhmpdheggkocibajddahbeiglb':{'category':'Ne','label':2,'pp':1,'target':'Generic'},\n",
    "'mpejojclnbakefnlfmnkaaianojbicdk':{'category':'Ph','label':2,'pp':1,'target':'Generic'},\n",
    "'mmeijimgabbpbgpdklnllpncmdofkcpn':{'category':'Pr','label':2,'pp':1,'target':'Generic'},\n",
    "'aookogakccicaoigoofnnmeclkignpdk':{'category':'Se','label':2,'pp':1,'target':'Generic'},\n",
    "'neebplgakaahbhdphmkckjjcegoiijjo':{'category':'Sh','label':2,'pp':1,'target':'Shoppingjp'},\n",
    "'jicldjademmddamblmdllfneeaeeclik':{'category':'So','label':2,'pp':1,'target':'Oktool'},\n",
    "'mlfkmhibffpoleieiomjkekmjipdekhg':{'category':'Sp','label':2,'pp':1,'target':'Video_youtube'},\n",
    "    'jiiidpmjdakhbgkbdchmhmnfbdebfnhp':{'category':'De','label':2,'pp':1,'target':'Generic'},\n",
    "    'behkgahlidmeemjefcbgieigiejiglpc':{'category':'Ne','label':2,'pp':1,'target':'Generic'},\n",
    "    #11\n",
    "'kammdlphdfejlopponbapgpbgakimokm':{'category':'Ac','label':3,'pp':2,'target':'Generic'},\n",
    "'fnhmjceoafkkibpijbfpfajbhkknadmb':{'category':'Bl','label':3,'pp':4,'target':'Tricky'},\n",
    "'fklgmciohehgadlafhljjhgdojfjihhk':{'category':'De','label':3,'pp':2,'target':'Generic'},\n",
    "'jpefkkpmalfnilnbghfnjodceifpemdb':{'category':'Fu','label':3,'pp':2,'target':'Ereality'},\n",
    "'pgfokhpgehbmeifbpdhegfnpaahabfja':{'category':'Ne','label':3,'pp':2,'target':'News'},\n",
    "'aiiimepjikpdipbpmknolbnjbeohbmaa':{'category':'Ph','label':3,'pp':2,'target':'Generic'},\n",
    "'jbebkmmlkhioeagiekpopmeecaepaihd':{'category':'Pr','label':3,'pp':2,'target':'Generic'},\n",
    "'didkfdopbffjkpolefhpcjkohcpalicd':{'category':'Se','label':3,'pp':2,'target':'Generic'},\n",
    "'pbjikboenpfhbbejgkoklgkhjpfogcam':{'category':'Sh','label':3,'pp':3,'target':'Shoppingjp'},\n",
    "'mhkhmbddkmdggbhaaaodilponhnccicb':{'category':'So','label':3,'pp':2,'target':'Video_youtube'},\n",
    "'lipplpkgbnhdfdchoibgafjdblpjdkpi':{'category':'Sp','label':3,'pp':3,'target':'Lichess'},\n",
    "    #14\n",
    "'bkpenclhmiealbebdopglffmfdiilejc':{'category':'Ac','label':4,'pp':1,'target':'Generic'},\n",
    "'lnphplhkejidgcncalbkbngbiafmjnml':{'category':'Bl','label':4,'pp':1,'target':'Generic'},\n",
    "'dgjhfomjieaadpoljlnidmbgkdffpack':{'category':'De','label':4,'pp':1,'target':'GitHub'},\n",
    "'hcbddpppkcnfjifbcfnhmelpemdoepkk':{'category':'Fu','label':4,'pp':1,'target':'Generic'},\n",
    "'kgaebnfbgpcnglnhjhglinfiecgccfij':{'category':'Ne','label':4,'pp':1,'target':'Generic'},\n",
    "'iedjpcecgmldlnkbojiocmdaedhepbpn':{'category':'Ph','label':4,'pp':1,'target':'Generic'},\n",
    "'nkbihfbeogaeaoehlefnkodbefgpgknn':{'category':'Pr','label':4,'pp':1,'target':'Generic'},\n",
    "'eedlgdlajadkbbjoobobefphmfkcchfk':{'category':'Se','label':4,'pp':1,'target':'Generic'},\n",
    "'gfkpklgmocbcbdabfellcnikamdaeajd':{'category':'Sh','label':4,'pp':2,'target':'Shoppingjp'},\n",
    "'bboamecjefgpaemgfpcjeediamdnkklc':{'category':'So','label':4,'pp':1,'target':'Video_youtube'},\n",
    "'kimjfkgkpmafgngclkdpjdlkdlghoikh':{'category':'Sp','label':4,'pp':1,'target':'Espn'},\n",
    "    'bhggankplfegmjjngfmhfajedmiikolo':{'category':'Ac','label':4,'pp':1,'target':'Generic'},\n",
    "    'ldjnabbinoccbodkejkdiolmadimbjkj':{'category':'Bl','label':4,'pp':2,'target':'Jobsalert'},\n",
    "    'obhadkdgdffnnbdfpigjklinjhbkinfh':{'category':'Fu','label':4,'pp':2,'target':'Shadowpay'}\n",
    "             }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a3dfc9f8",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "930872fd",
   "metadata": {},
   "source": [
    "## Extension-free normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5027fefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.read_csv('/xxxxxxxx/free.txt', sep=\" \", header=None)[0]\n",
    "free_cycle = pd.DataFrame()\n",
    "\n",
    "for i in range(int(len(f)/7)):\n",
    "    type = f[i*7]\n",
    "    timestamp = f[i*7+1]\n",
    "    time = f[i*7+2]\n",
    "    core = f[i*7+3]\n",
    "    dram = f[i*7+4]\n",
    "    core5 = f[i*7+5]\n",
    "    dram5 = f[i*7+6]\n",
    "    loading = float(core)+float(dram)\n",
    "    static = float(core5)+float(dram5)\n",
    "    tmp = {'type':type,'time':time,'loading':loading,'static':static}\n",
    "    free_cycle = pd.concat([free_cycle, pd.DataFrame([tmp])], ignore_index=True)\n",
    "\n",
    "free = {'normal':{}}\n",
    "\n",
    "for type in list(dict.fromkeys(free_cycle['type'])):\n",
    "    time = free_cycle[free_cycle['type']==type]['time'].astype('float64')\n",
    "    loading = free_cycle[free_cycle['type']==type]['loading'].astype('float64')\n",
    "    static = free_cycle[free_cycle['type']==type]['static'].astype('float64')\n",
    "    \n",
    "    batch = 10\n",
    "    batch_times = 10\n",
    "    for i in range(batch):\n",
    "        \n",
    "        # # x/median Normalization\n",
    "        # #  Normalize website by core/dram/...\n",
    "        time.iloc[i*batch:i*batch+batch_times] = time[i*batch:i*batch+batch_times]/time[i*batch:i*batch+batch_times].median()\n",
    "        loading.iloc[i*batch:i*batch+batch_times] = loading[i*batch:i*batch+batch_times]/loading[i*batch:i*batch+batch_times].median()\n",
    "        static.iloc[i*batch:i*batch+batch_times] = static[i*batch:i*batch+batch_times]/static[i*batch:i*batch+batch_times].median()\n",
    "        \n",
    "       \n",
    "    free['normal'][type] = {'time':time,'loading':loading,'static':static}\n",
    "    \n",
    "    Ntime = []\n",
    "    Ncore = []\n",
    "    Ndram = []\n",
    "    Ncore5 = []\n",
    "    Ndram5 = []\n",
    "    Nloading = []\n",
    "    Nstatic = []\n",
    "    Ntotal = []\n",
    "    for i in range(batch):\n",
    "        Ntime.append(free['normal'][type]['time'][i*batch:i*batch+batch_times].mean())\n",
    "        Nloading.append(free['normal'][type]['loading'][i*batch:i*batch+batch_times].mean())\n",
    "        Nstatic.append(free['normal'][type]['static'][i*batch:i*batch+batch_times].mean())\n",
    "\n",
    "free['normal']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "650619e4",
   "metadata": {},
   "source": [
    "## Normalization - fully loaded mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34523463",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.read_csv('/xxxxxxxx/full.txt', sep=\" \", header=None)[0]\n",
    "# id = []\n",
    "full = pd.DataFrame()\n",
    "for i in range(int(len(f)/7)):\n",
    "    id = f[i*7]\n",
    "    timestamp = f[i*7+1]\n",
    "    time = f[i*7+2]\n",
    "    core = f[i*7+3]\n",
    "    dram = f[i*7+4]\n",
    "    core5 = f[i*7+5]\n",
    "    dram5 = f[i*7+6]\n",
    "    loading = float(core)+float(dram)\n",
    "    static = float(core5)+float(dram5)\n",
    "    total = float(loading) + float(static)\n",
    "    target=extensions[id]['target']\n",
    "    tmp = {'id':id,\n",
    "           'category':cate[extensions[id]['category']],\n",
    "           'label':extensions[id]['label'],\n",
    "           '#pp':extensions[id]['pp'],\n",
    "           'target':target.lower(),\n",
    "           # 'timestamp':timestamp,\n",
    "           'otime':time,\n",
    "           'ocore':core,'odram':dram,'ocore5':core5,'odram5':dram5,\n",
    "           'oloading':loading,'ostatic':static,'ototal': total\n",
    "          }\n",
    "    full = pd.concat([full, pd.DataFrame([tmp])], ignore_index=True)  \n",
    "\n",
    "for type in list(dict.fromkeys(full['target'])):\n",
    "    id_list = list(dict.fromkeys(full[full['target']==type]['id']))\n",
    "    \n",
    "    time_all = full[full['target']==type]\n",
    "    core_all = full[full['target']==type]\n",
    "    dram_all = full[full['target']==type]\n",
    "    core5_all = full[full['target']==type]\n",
    "    dram5_all = full[full['target']==type]\n",
    "    \n",
    "    \n",
    "    time_base = free_cycle[free_cycle['type']==type]['time'].astype('float64')\n",
    "    core_base = free_cycle[free_cycle['type']==type]['core'].astype('float64')\n",
    "    dram_base = free_cycle[free_cycle['type']==type]['dram'].astype('float64')\n",
    "    core5_base = free_cycle[free_cycle['type']==type]['core5'].astype('float64')\n",
    "    dram5_base = free_cycle[free_cycle['type']==type]['dram5'].astype('float64')\n",
    "    \n",
    "    loading_base = free_cycle[free_cycle['type']==type]['loading'].astype('float64')\n",
    "    static_base = free_cycle[free_cycle['type']==type]['static'].astype('float64')\n",
    "    total_base = free_cycle[free_cycle['type']==type]['total'].astype('float64')\n",
    "    # # extensions in different web types\n",
    "    for id in id_list:\n",
    "        idx = full.index[full['id']==id]\n",
    "        \n",
    "        batch = idx[0]\n",
    "        batch_times = 10\n",
    "        for i in range(batch_times):\n",
    "            \n",
    "            # # Normalize x/median by website based on free version\n",
    "            full.loc[batch+i*batch_times:batch+i*batch_times+batch_times-1,'time'] = full[full['id']==id]['otime'][i*batch_times:i*batch_times+batch_times].astype('float64')/time_base[i*batch_times:i*batch_times+batch_times].median()\n",
    "            full.loc[batch+i*batch_times:batch+i*batch_times+batch_times-1,'core'] = full[full['id']==id]['ocore'][i*batch_times:i*batch_times+batch_times].astype('float64')/core_base[i*batch_times:i*batch_times+batch_times].median()\n",
    "            full.loc[batch+i*batch_times:batch+i*batch_times+batch_times-1,'dram'] = full[full['id']==id]['odram'][i*batch_times:i*batch_times+batch_times].astype('float64')/dram_base[i*batch_times:i*batch_times+batch_times].median()\n",
    "            full.loc[batch+i*batch_times:batch+i*batch_times+batch_times-1,'core5'] = full[full['id']==id]['ocore5'][i*batch_times:i*batch_times+batch_times].astype('float64')/core5_base[i*batch_times:i*batch_times+batch_times].median()\n",
    "            full.loc[batch+i*batch_times:batch+i*batch_times+batch_times-1,'dram5'] = full[full['id']==id]['odram5'][i*batch_times:i*batch_times+batch_times].astype('float64')/dram5_base[i*batch_times:i*batch_times+batch_times].median()\n",
    "            \n",
    "            full.loc[batch+i*batch_times:batch+i*batch_times+batch_times-1,'loading'] = full[full['id']==id]['oloading'][i*batch_times:i*batch_times+batch_times].astype('float64')/loading_base[i*batch_times:i*batch_times+batch_times].median()\n",
    "            full.loc[batch+i*batch_times:batch+i*batch_times+batch_times-1,'static'] = full[full['id']==id]['ostatic'][i*batch_times:i*batch_times+batch_times].astype('float64')/static_base[i*batch_times:i*batch_times+batch_times].median()\n",
    "            full.loc[batch+i*batch_times:batch+i*batch_times+batch_times-1,'total'] = full[full['id']==id]['ototal'][i*batch_times:i*batch_times+batch_times].astype('float64')/total_base[i*batch_times:i*batch_times+batch_times].median()\n",
    "    \n",
    "print(len(full[full.time.isna() | full.core.isna() | full.dram.isna() | full.core5.isna() | full.dram5.isna() | full.loading.isna() | full.static.isna() | full.total.isna()]))\n",
    "full.sort_values(by=['label','category'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b9b2b32d",
   "metadata": {},
   "source": [
    "## Change ratio - fully loaded mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ac47fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_cycle = pd.DataFrame()\n",
    "for id in list(dict.fromkeys(full['id'])):\n",
    "    target =full[full['id']==id]['target'].tolist()[0].lower()\n",
    "    \n",
    "    otime = full[full['id']==id]['otime'].astype('float64')\n",
    "    oloading = full[full['id']==id]['oloading'].astype('float64')\n",
    "    ostatic = full[full['id']==id]['ostatic'].astype('float64')\n",
    "    \n",
    "    time = full[full['id']==id]['time'].astype('float64')\n",
    "    loading = full[full['id']==id]['loading'].astype('float64')\n",
    "    static = full[full['id']==id]['static'].astype('float64')\n",
    "    \n",
    "    batch = 10\n",
    "    batch_times = 10\n",
    "    timeRatio = []\n",
    "    loadingRatio = []\n",
    "    staticRatio = []\n",
    "    \n",
    "    for i in range(batch):\n",
    "        timeRatio.append((time.iloc[i*batch:i*batch+batch_times].median()-free['normal'][type]['time'][i*batch:i*batch+batch_times].median())/(free['normal'][type]['time'][i*batch:i*batch+batch_times]).median())\n",
    "        loadingRatio.append((loading.iloc[i*batch:i*batch+batch_times].median()-free['normal'][type]['loading'][i*batch:i*batch+batch_times].median())/(free['normal'][type]['loading'][i*batch:i*batch+batch_times]).median())\n",
    "        staticRatio.append((static.iloc[i*batch:i*batch+batch_times].median()-free['normal'][type]['static'][i*batch:i*batch+batch_times].median())/(free['normal'][type]['static'][i*batch:i*batch+batch_times]).median())\n",
    "\n",
    "    tmp = {'id':id,\n",
    "           'category':cate[extensions[id]['category']],\n",
    "           'label':extensions[id]['label'],\n",
    "           '#pp':extensions[id]['pp'],\n",
    "           'target':target,\n",
    "           'Median-timeRatio':mean(timeRatio)*100,\n",
    "           'Median-loadingRatio':mean(loadingRatio)*100,\n",
    "           'Median-staticRatio':mean(staticRatio)*100,\n",
    "          }\n",
    "    full_cycle = pd.concat([full_cycle, pd.DataFrame([tmp])], ignore_index=True) \n",
    "\n",
    "full_cycle.sort_values(by=['label','category'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85e312f2",
   "metadata": {},
   "source": [
    "## Statistically tests for the fully loaded mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2553a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percChange(full_cycle2, interp):\n",
    "    if interp == \"all\":\n",
    "        # print(\"Small Cliff's d\")\n",
    "        printPercChange(full_cycle2, 0.147,1.1)\n",
    "    if interp == \"small\":\n",
    "        # print(\"Small Cliff's d\")\n",
    "        printPercChange(full_cycle2, 0.147,0.330)\n",
    "    if interp == \"median\":\n",
    "        # print(\"Median Cliff's d\")\n",
    "        printPercChange(full_cycle2, 0.330,0.474)\n",
    "    if interp == \"large\":\n",
    "        # print(\"Large Cliff's d\")\n",
    "        printPercChange(full_cycle2, 0.474,1.1)\n",
    "            \n",
    "def printPercChange(full_cycle2, lf, rt):\n",
    "    for typ in ['time','loading','static']:\n",
    "        numI = len(full_cycle2[(full_cycle2[f'Median-{typ}Ratio']>0) & (full_cycle2[f'wilcoxon-{typ}']<0.05) & (full_cycle2[f'cliffs_d-{typ}'].between(left=lf, right=rt, inclusive=\"left\"))])\n",
    "        num = len(full_cycle2[(full_cycle2[f'wilcoxon-{typ}']<0.05) & (full_cycle2[f'cliffs_d-{typ}'].between(left=lf, right=rt, inclusive=\"left\"))])\n",
    "        perc = round(numI/num*100,2) if num!=0 else 0\n",
    "        \n",
    "        print(len(full_cycle2[(full_cycle2[f'Median-{typ}Ratio']>0) & (full_cycle2[f'wilcoxon-{typ}']<0.05) & (full_cycle2[f'cliffs_d-{typ}'].between(left=lf, right=rt, inclusive=\"left\"))]), f' ({perc}%) {typ} in median increase by',\n",
    "              round((full_cycle2[(full_cycle2[f'Median-{typ}Ratio']>0) & (full_cycle2[f'wilcoxon-{typ}']<0.05) & (full_cycle2[f'cliffs_d-{typ}'].between(left=lf, right=rt, inclusive=\"left\"))][f'Median-{typ}Ratio'].median()),2), '%')\n",
    "        numI = len(full_cycle2[(full_cycle2[f'Median-{typ}Ratio']<0) & (full_cycle2[f'wilcoxon-{typ}']<0.05) & (full_cycle2[f'cliffs_d-{typ}'].between(left=lf, right=rt, inclusive=\"left\"))])\n",
    "        num = len(full_cycle2[(full_cycle2[f'wilcoxon-{typ}']<0.05) & (full_cycle2[f'cliffs_d-{typ}'].between(left=lf, right=rt, inclusive=\"left\"))])\n",
    "        perc = round(numI/num*100,2) if num!=0 else 0\n",
    "        \n",
    "        print(len(full_cycle2[(full_cycle2[f'Median-{typ}Ratio']<0) & (full_cycle2[f'wilcoxon-{typ}']<0.05) & (full_cycle2[f'cliffs_d-{typ}'].between(left=lf, right=rt, inclusive=\"left\"))]), f' ({perc}%) {typ} in median drop by',\n",
    "              round((full_cycle2[(full_cycle2[f'Median-{typ}Ratio']<0) & (full_cycle2[f'wilcoxon-{typ}']<0.05) & (full_cycle2[f'cliffs_d-{typ}'].between(left=lf, right=rt, inclusive=\"left\"))][f'Median-{typ}Ratio'].median()),2), '%')\n",
    "        print(len(full_cycle2[(full_cycle2[f'wilcoxon-{typ}']<0.05) & (full_cycle2[f'cliffs_d-{typ}'].between(left=lf, right=rt, inclusive=\"left\"))]), f' {typ} in median changes by',\n",
    "              round((full_cycle2[(full_cycle2[f'wilcoxon-{typ}']<0.05) & (full_cycle2[f'cliffs_d-{typ}'].between(left=lf, right=rt, inclusive=\"left\"))][f'Median-{typ}Ratio'].median()),2), '%')\n",
    "        print('\\n')\n",
    "        \n",
    "print('Wilcoxon + cliff d')\n",
    "for cd in range(4):\n",
    "    print(\"Small Cliff's d \\n\") if cd ==1 else ''\n",
    "    print(\"Median Cliff's d \\n\") if cd ==2 else \"\"\n",
    "    print(\"Large Cliff's d \\n\") if cd ==3 else ''\n",
    "    \n",
    "    full_cycle2 = full_cycle.copy()\n",
    "    for typ in ['time','loading','static']:\n",
    "        for ext in list(full_cycle2['id']):\n",
    "            target =full[full['id']==ext]['target'].tolist()[0].lower()\n",
    "            s,y = mannwhitneyu(full[full['id']==ext][typ].astype('float64'),free['normal'][target][typ].astype('float64'))#,method='exact')\n",
    "            ws,wy = wilcoxon(full[full['id']==ext][typ].astype('float64'),free['normal'][target][typ].astype('float64'))\n",
    "            d,res = cliffs_delta(full[full['id']==ext][typ].astype('float64'),free['normal'][target][typ].astype('float64'))\n",
    "\n",
    "            idx = full_cycle2.index[full_cycle2['id']==ext][0]\n",
    "            full_cycle2.at[idx,f'wilcoxon-{typ}'] = round(wy,2)\n",
    "            full_cycle2.at[idx,f'cliffs_d-{typ}'] = round(abs(d),2)\n",
    "\n",
    "    percChange(full_cycle2, 'all') if cd ==0 else ''\n",
    "    percChange(full_cycle2, 'small') if cd ==1 else ''\n",
    "    percChange(full_cycle2, 'median') if cd ==2 else \"\"\n",
    "    percChange(full_cycle2, 'large') if cd ==3 else ''    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e3326e2",
   "metadata": {},
   "source": [
    "## Generalize the preprocessing procedures for other modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc365cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    print(filename)\n",
    "    f = pd.read_csv(f'/xxxxxxxx/{filename}.txt', sep=\" \", header=None)[0]\n",
    "    notGrant = pd.DataFrame()\n",
    "    for i in range(int(len(f)/7)):\n",
    "        id = f[i*7]\n",
    "        timestamp = f[i*7+1]\n",
    "        time = f[i*7+2]\n",
    "        core = f[i*7+3]\n",
    "        dram = f[i*7+4]\n",
    "        core5 = f[i*7+5]\n",
    "        dram5 = f[i*7+6]\n",
    "        loading = float(core)+float(dram)\n",
    "        static = float(core5)+float(dram5)\n",
    "        target=extensions[id]['target']\n",
    "        tmp = {'id':id,\n",
    "               'category':cate[extensions[id]['category']],\n",
    "               'label':extensions[id]['label'],\n",
    "               'pp':extensions[id]['pp'],\n",
    "               'target':target.lower() if filename != 'inactive' else 'generic',\n",
    "               'otime':time,\n",
    "               'oloading':loading,'ostatic':static\n",
    "              }\n",
    "        notGrant = pd.concat([notGrant, pd.DataFrame([tmp])], ignore_index=True) \n",
    "    print( len(dict.fromkeys(notGrant['id'])),'in total')\n",
    "    return notGrant\n",
    "\n",
    "def normalization(full):\n",
    "    for type in list(dict.fromkeys(full['target'])):\n",
    "        id_list = list(dict.fromkeys(full[full['target']==type]['id']))\n",
    "\n",
    "\n",
    "        time_base = free_cycle[free_cycle['type']==type]['time'].astype('float64')\n",
    "        loading_base = free_cycle[free_cycle['type']==type]['loading'].astype('float64')\n",
    "        static_base = free_cycle[free_cycle['type']==type]['static'].astype('float64')\n",
    "        # # extensions in different web types\n",
    "        for id in id_list:\n",
    "            idx = full.index[full['id']==id]\n",
    "\n",
    "            batch = idx[0]\n",
    "            batch_times = 10\n",
    "            for i in range(batch_times):\n",
    "\n",
    "                # # Normalize x/median by website based on free version\n",
    "                full.loc[batch+i*batch_times:batch+i*batch_times+batch_times-1,'time'] = full[full['id']==id]['otime'][i*batch_times:i*batch_times+batch_times].astype('float64')/time_base[i*batch_times:i*batch_times+batch_times].median()\n",
    "                full.loc[batch+i*batch_times:batch+i*batch_times+batch_times-1,'loading'] = full[full['id']==id]['oloading'][i*batch_times:i*batch_times+batch_times].astype('float64')/loading_base[i*batch_times:i*batch_times+batch_times].median()\n",
    "                full.loc[batch+i*batch_times:batch+i*batch_times+batch_times-1,'static'] = full[full['id']==id]['ostatic'][i*batch_times:i*batch_times+batch_times].astype('float64')/static_base[i*batch_times:i*batch_times+batch_times].median()\n",
    "    return full\n",
    "def stat_test(full_cycle2, full,fullload,free):\n",
    "        \n",
    "    percChange2base(full_cycle2, full,fullload,free)\n",
    "    return full_cycle2\n",
    "\n",
    "def percChange2base(full_cycle2, full,fullload,free):\n",
    "    \n",
    "    print('Based on free version')\n",
    "    print('Wilcoxon + cliff d')\n",
    "    for typ in ['time','loading','static']:\n",
    "        for ext in list(full_cycle2['id']):\n",
    "            target =full[full['id']==ext]['target'].tolist()[0].lower()\n",
    "            # # Ext 2 Base\n",
    "            ws,wy = wilcoxon(full[full['id']==ext][typ].astype('float64'),free['normal'][target][typ].astype('float64'))\n",
    "            d,res = cliffs_delta(full[full['id']==ext][typ].astype('float64'),free['normal'][target][typ].astype('float64'))\n",
    "\n",
    "            idx = full_cycle2.index[full_cycle2['id']==ext][0]\n",
    "            full_cycle2.at[idx,f'wilcoxon-{typ}2base'] = round(wy,2)\n",
    "            full_cycle2.at[idx,f'cliffs_d-{typ}2base'] = round(abs(d),2)\n",
    "\n",
    "    for typ in ['time','loading','static']:\n",
    "        typ2 = typ\n",
    "        lf=0.147\n",
    "        rt=1.1\n",
    "        \n",
    "        numI =len(full_cycle2[(full_cycle2[f'{typ}2base']>0) & (full_cycle2[f'wilcoxon-{typ2}2base']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2base'].between(left=lf, right=rt, inclusive=\"left\"))])\n",
    "        num = len(full_cycle2[(full_cycle2[f'wilcoxon-{typ2}2base']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2base'].between(left=lf, right=rt, inclusive=\"left\"))])\n",
    "        perc = round(numI/num*100,2) if num!=0 else 0\n",
    "\n",
    "        print(numI, f'({perc} %)', f' {typ} in median increase by',\n",
    "              round((full_cycle2[(full_cycle2[f'{typ}2base']>0) & (full_cycle2[f'wilcoxon-{typ2}2base']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2base'].between(left=lf, right=rt, inclusive=\"left\"))][f'{typ}2base'].median()),2), '%')\n",
    "\n",
    "        numD =len(full_cycle2[(full_cycle2[f'{typ}2base']<0) & (full_cycle2[f'wilcoxon-{typ2}2base']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2base'].between(left=lf, right=rt, inclusive=\"left\"))])\n",
    "        num = len(full_cycle2[(full_cycle2[f'wilcoxon-{typ2}2base']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2base'].between(left=lf, right=rt, inclusive=\"left\"))])\n",
    "        perc = round(numD/num*100,2) if num!=0 else 0\n",
    "\n",
    "        print(numD, f'({perc} %)', f' {typ} in median drop by',\n",
    "              round((full_cycle2[(full_cycle2[f'{typ}2base']<0) & (full_cycle2[f'wilcoxon-{typ2}2base']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2base'].between(left=lf, right=rt, inclusive=\"left\"))][f'{typ}2base'].median()),2), '%')\n",
    "    \n",
    "        print(len(full_cycle2[(full_cycle2[f'wilcoxon-{typ2}2base']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2base'].between(left=lf, right=rt, inclusive=\"left\"))]), f' {typ} in median changes by',\n",
    "              round((full_cycle2[(full_cycle2[f'wilcoxon-{typ2}2base']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2base'].between(left=lf, right=rt, inclusive=\"left\"))][f'{typ}2base'].median()),2), '%')\n",
    "        print('\\n')\n",
    "            \n",
    "    for cd in range(3):\n",
    "        if cd ==0:\n",
    "            lf=0.147\n",
    "            rt=0.330\n",
    "            print(\"Small Cliff's d \\n\")\n",
    "        if cd ==1:\n",
    "            lf=0.330 \n",
    "            rt=0.474\n",
    "            print(\"Median Cliff's d \\n\")\n",
    "        if cd ==2:\n",
    "            lf=0.474 \n",
    "            rt=1.1\n",
    "            print(\"Large Cliff's d \\n\")\n",
    "    \n",
    "        for typ in ['time','loading','static']:\n",
    "            typ2 = typ\n",
    "            numI =len(full_cycle2[(full_cycle2[f'{typ}2base']>0) & (full_cycle2[f'wilcoxon-{typ2}2base']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2base'].between(left=lf, right=rt, inclusive=\"left\"))])\n",
    "            num = len(full_cycle2[(full_cycle2[f'wilcoxon-{typ2}2base']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2base'].between(left=lf, right=rt, inclusive=\"left\"))])\n",
    "            perc = round(numI/num*100,2) if num!=0 else 0\n",
    "\n",
    "            print(numI, f'({perc} %)', f' {typ} in median increase by',\n",
    "                  round((full_cycle2[(full_cycle2[f'{typ}2base']>0) & (full_cycle2[f'wilcoxon-{typ2}2base']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2base'].between(left=lf, right=rt, inclusive=\"left\"))][f'{typ}2base'].median()),2), '%')\n",
    "            \n",
    "            # typ2 = typ.replace('Static','5') if 'Static' in typ else typ\n",
    "            numD =len(full_cycle2[(full_cycle2[f'{typ}2base']<0) & (full_cycle2[f'wilcoxon-{typ2}2base']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2base'].between(left=lf, right=rt, inclusive=\"left\"))])\n",
    "            num = len(full_cycle2[(full_cycle2[f'wilcoxon-{typ2}2base']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2base'].between(left=lf, right=rt, inclusive=\"left\"))])\n",
    "            perc = round(numD/num*100,2) if num!=0 else 0\n",
    "\n",
    "            print(numD, f'({perc} %)', f' {typ} in median drop by',\n",
    "                  round((full_cycle2[(full_cycle2[f'{typ}2base']<0) & (full_cycle2[f'wilcoxon-{typ2}2base']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2base'].between(left=lf, right=rt, inclusive=\"left\"))][f'{typ}2base'].median()),2), '%')\n",
    "            print(len(full_cycle2[(full_cycle2[f'wilcoxon-{typ2}2base']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2base'].between(left=lf, right=rt, inclusive=\"left\"))]), f' {typ} in median changes by',\n",
    "                  round((full_cycle2[(full_cycle2[f'wilcoxon-{typ2}2base']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2base'].between(left=lf, right=rt, inclusive=\"left\"))][f'{typ}2base'].median()),2), '%')\n",
    "            print('\\n')\n",
    "        print('\\n')\n",
    "        \n",
    "def percChange2full(full_cycle2,full,fullload,free):\n",
    "    print('Based on full-loaded extension consumption')\n",
    "    print('Wilcoxon + cliff d')\n",
    "    for typ in ['time','loading','static']:\n",
    "        for ext in list(full_cycle2['id']):\n",
    "            target =full[full['id']==ext]['target'].tolist()[0].lower()\n",
    "            # # Ext 2 Base\n",
    "            ws,wy = wilcoxon(full[full['id']==ext][typ].astype('float64'),fullload[fullload['id']==ext][typ].astype('float64'))\n",
    "            d,res = cliffs_delta(full[full['id']==ext][typ].astype('float64'),fullload[fullload['id']==ext][typ].astype('float64'))\n",
    "\n",
    "            idx = full_cycle2.index[full_cycle2['id']==ext][0]\n",
    "            full_cycle2.at[idx,f'wilcoxon-{typ}2full'] = round(wy,2)\n",
    "            full_cycle2.at[idx,f'cliffs_d-{typ}2full'] = round(abs(d),2)\n",
    "\n",
    "    for typ in ['time','loading','static']:\n",
    "        lf=0.147\n",
    "        rt=1.1\n",
    "\n",
    "        typ2 = typ\n",
    "        numI = len(full_cycle2[(full_cycle2[f'{typ}2full']>0) & (full_cycle2[f'wilcoxon-{typ2}2full']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2full'].between(left=lf, right=rt, inclusive=\"left\"))])\n",
    "        num = len(full_cycle2[(full_cycle2[f'wilcoxon-{typ2}2full']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2full'].between(left=lf, right=rt, inclusive=\"left\"))])\n",
    "        perc = round(numI/num*100,2) if num!=0 else 0\n",
    "        print(numI, f'({perc} %)', f' {typ} in median increase by',\n",
    "              round((full_cycle2[(full_cycle2[f'{typ}2full']>0) & (full_cycle2[f'wilcoxon-{typ2}2full']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2full'].between(left=lf, right=rt, inclusive=\"left\"))][f'{typ}2full'].median()),2), '%')\n",
    "\n",
    "        numD = len(full_cycle2[(full_cycle2[f'{typ}2full']<0) & (full_cycle2[f'wilcoxon-{typ2}2full']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2full'].between(left=lf, right=rt, inclusive=\"left\"))])\n",
    "        num = len(full_cycle2[(full_cycle2[f'wilcoxon-{typ2}2full']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2full'].between(left=lf, right=rt, inclusive=\"left\"))])\n",
    "        perc = round(numD/num*100,2) if num!=0 else 0\n",
    "        print(numD, f'({perc} %)', f' {typ} in median drop by',\n",
    "              round((full_cycle2[(full_cycle2[f'{typ}2full']<0) & (full_cycle2[f'wilcoxon-{typ2}2full']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2full'].between(left=lf, right=rt, inclusive=\"left\"))][f'{typ}2full'].median()),2), '%')\n",
    "\n",
    "        print(len(full_cycle2[(full_cycle2[f'wilcoxon-{typ2}2full']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2full'].between(left=lf, right=rt, inclusive=\"left\"))]),f' {typ} in median changes by',\n",
    "              round((full_cycle2[(full_cycle2[f'wilcoxon-{typ2}2full']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2full'].between(left=lf, right=rt, inclusive=\"left\"))][f'{typ}2full'].median()),2), '%')\n",
    "        print('\\n')\n",
    "            \n",
    "    for cd in range(3):\n",
    "        if cd ==0:\n",
    "            lf=0.147\n",
    "            rt=0.330\n",
    "            print(\"Small Cliff's d \\n\")\n",
    "        if cd ==1:\n",
    "            lf=0.330 \n",
    "            rt=0.474\n",
    "            print(\"Median Cliff's d \\n\")\n",
    "        if cd ==2:\n",
    "            lf=0.474 \n",
    "            rt=1.1\n",
    "            print(\"Large Cliff's d \\n\")\n",
    "        for typ in ['time','loading','static']:\n",
    "\n",
    "            typ2 = typ\n",
    "            numI = len(full_cycle2[(full_cycle2[f'{typ}2full']>0) & (full_cycle2[f'wilcoxon-{typ2}2full']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2full'].between(left=lf, right=rt, inclusive=\"left\"))])\n",
    "            num = len(full_cycle2[(full_cycle2[f'wilcoxon-{typ2}2full']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2full'].between(left=lf, right=rt, inclusive=\"left\"))])\n",
    "            perc = round(numI/num*100,2) if num!=0 else 0\n",
    "            print(numI, f'({perc} %)', f' {typ} in median increase by',\n",
    "                  round((full_cycle2[(full_cycle2[f'{typ}2full']>0) & (full_cycle2[f'wilcoxon-{typ2}2full']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2full'].between(left=lf, right=rt, inclusive=\"left\"))][f'{typ}2full'].median()),2), '%')\n",
    "\n",
    "            numD = len(full_cycle2[(full_cycle2[f'{typ}2full']<0) & (full_cycle2[f'wilcoxon-{typ2}2full']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2full'].between(left=lf, right=rt, inclusive=\"left\"))])\n",
    "            num = len(full_cycle2[(full_cycle2[f'wilcoxon-{typ2}2full']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2full'].between(left=lf, right=rt, inclusive=\"left\"))])\n",
    "            perc = round(numD/num*100,2) if num!=0 else 0\n",
    "            print(numD, f'({perc} %)', f' {typ} in median drop by',\n",
    "                  round((full_cycle2[(full_cycle2[f'{typ}2full']<0) & (full_cycle2[f'wilcoxon-{typ2}2full']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2full'].between(left=lf, right=rt, inclusive=\"left\"))][f'{typ}2full'].median()),2), '%')\n",
    "            print(len(full_cycle2[(full_cycle2[f'wilcoxon-{typ2}2full']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2full'].between(left=lf, right=rt, inclusive=\"left\"))]),f' {typ} in median changes by',\n",
    "                  round((full_cycle2[(full_cycle2[f'wilcoxon-{typ2}2full']<0.05) & (full_cycle2[f'cliffs_d-{typ2}2full'].between(left=lf, right=rt, inclusive=\"left\"))][f'{typ}2full'].median()),2), '%')\n",
    "            print('\\n')\n",
    "        print('\\n')\n",
    "\n",
    "def getRatio(notGrant,full,free):\n",
    "    notGrant_cycle = pd.DataFrame()\n",
    "    for id in list(dict.fromkeys(notGrant['id'])):\n",
    "        target =notGrant[notGrant['id']==id]['target'].tolist()[0].lower()\n",
    "\n",
    "        time = notGrant[notGrant['id']==id]['time'].astype('float64')\n",
    "        loading = notGrant[notGrant['id']==id]['loading'].astype('float64')\n",
    "        static = notGrant[notGrant['id']==id]['static'].astype('float64')\n",
    "        \n",
    "        batch = 10\n",
    "        batch_times = 10\n",
    "\n",
    "        time2base = []\n",
    "        loading2base = []\n",
    "        static2base = []\n",
    "\n",
    "        for i in range(batch):\n",
    "            time2base.append((time.iloc[i*batch:i*batch+batch_times].median()-free['normal'][type]['time'][i*batch:i*batch+batch_times].median())/(free['normal'][type]['time'][i*batch:i*batch+batch_times]).median())\n",
    "            loading2base.append((loading.iloc[i*batch:i*batch+batch_times].median()-free['normal'][type]['loading'][i*batch:i*batch+batch_times].median())/(free['normal'][type]['loading'][i*batch:i*batch+batch_times]).median())\n",
    "            static2base.append((static.iloc[i*batch:i*batch+batch_times].median()-free['normal'][type]['static'][i*batch:i*batch+batch_times].median())/(free['normal'][type]['static'][i*batch:i*batch+batch_times]).median())\n",
    "        \n",
    "        tmp = {'id':id,\n",
    "               'category':cate[extensions[id]['category']],\n",
    "               'label':extensions[id]['label'],\n",
    "               '#pp':extensions[id]['pp'],\n",
    "               'target':target,\n",
    "               'time2base':mean(time2base)*100,\n",
    "               'loading2base':mean(loading2base)*100,\n",
    "               'static2base':mean(static2base)*100,\n",
    "              }\n",
    "        notGrant_cycle = pd.concat([notGrant_cycle, pd.DataFrame([tmp])], ignore_index=True)\n",
    "    return notGrant_cycle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58b793c1",
   "metadata": {},
   "source": [
    "## Normalization - no Grant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb82be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "notGrant=read_file('notGrant')\n",
    "notGrant = normalization(notGrant)\n",
    "notGrant_cycle = getRatio(notGrant,full,free)\n",
    "notGrant_cycle = stat_test(notGrant_cycle, notGrant,full,free)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0f9f685",
   "metadata": {},
   "source": [
    "## Normalization - no Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1bd67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "notLogin=read_file('notLogin')\n",
    "notLogin = normalization(notLogin)\n",
    "notLogin_cycle = getRatio(notLogin,full,free)\n",
    "notLogin_cycle = stat_test(notLogin_cycle, notLogin,full,free)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2736b58",
   "metadata": {},
   "source": [
    "## Normalization - Inactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9cba6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inactive=read_file('inactive')\n",
    "inactive = normalization(inactive)\n",
    "inactive_cycle = getRatio(inactive,full,free)\n",
    "inactive_cycle = stat_test(inactive_cycle, inactive,full,free)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "900c76d7",
   "metadata": {},
   "source": [
    "## Normalization - Fully inactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0a755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullinactive=read_file('fullyInactive')\n",
    "fullinactive = normalization(fullinactive)\n",
    "fullinactive_cycle = getRatio(fullinactive,full,free)\n",
    "fullinactive_cycle = stat_test(fullinactive_cycle, fullinactive,full,free)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17ef632a",
   "metadata": {},
   "source": [
    "# Export the extension measurement to an Excel (!will be used to build the linear mixed effects model!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051e9402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_convert(u):\n",
    "    if '+' in u:\n",
    "        return int(float(u.split('+')[0].strip().replace(',','')))\n",
    "    else: return int(float(u.split(' ')[0].strip().replace(',','')))\n",
    "\n",
    "def size_convert(s):\n",
    "    scaler = {'KiB': 1,'MiB': 1024}\n",
    "    s = re.split('([-+]?\\d+\\.\\d+)|([-+]?\\d+)',s.strip())\n",
    "    s = [r.strip() for r in s if r is not None and r.strip() != '']\n",
    "    return float(s[0])*scaler[s[1]]\n",
    "\n",
    "active_NG = ['kpghljlpdknmomchobaoecdlkcpocaga', 'bkkjeefjfjcfdfifddmkdmcpmaakmelp', 'gmopgnhbhiniibbiilmbjilcmgaocokj',\n",
    "'neebplgakaahbhdphmkckjjcegoiijjo', 'fadndhdgpmmaapbmfcknlfgcflmmmieb', 'pkihbahhbihfoebgdfkibnblbhjfgefc',\n",
    "'jicldjademmddamblmdllfneeaeeclik', 'fnhmjceoafkkibpijbfpfajbhkknadmb', 'mhkhmbddkmdggbhaaaodilponhnccicb',\n",
    "'lipplpkgbnhdfdchoibgafjdblpjdkpi', 'kimjfkgkpmafgngclkdpjdlkdlghoikh', 'obhadkdgdffnnbdfpigjklinjhbkinfh']\n",
    "\n",
    "# grant needed\n",
    "isGrant =['ffnhmkgpdmkajhomnckhabkfeakhcamm', 'fmidkjgknpkbmninbmklhcgaalfalbdh','kfimphpokifbjgmjflanmfeppcjimgah', \n",
    "'lcpkicdemehhmkjolekhlglljnkggfcf', 'fhjanlpjlfhhbhbnjohflphmfccbhmoi','naankklphfojljboaokgfbheobbgenka', \n",
    "'mlfkmhibffpoleieiomjkekmjipdekhg','bboamecjefgpaemgfpcjeediamdnkklc', 'eedlgdlajadkbbjoobobefphmfkcchfk', \n",
    "'iedjpcecgmldlnkbojiocmdaedhepbpn']\n",
    "\n",
    "# login needed\n",
    "isLogin =['ffnhmkgpdmkajhomnckhabkfeakhcamm','cimpffimgeipdhnhjohpbehjkcdpjolg', 'nngceckbapebfimnlniiiahkandclblb',\n",
    " 'kfimphpokifbjgmjflanmfeppcjimgah','lokmacldfjfgajcebibmmfohacnikhhd', 'fhjanlpjlfhhbhbnjohflphmfccbhmoi','mlfkmhibffpoleieiomjkekmjipdekhg',\n",
    " 'gmopgnhbhiniibbiilmbjilcmgaocokj','ikdgincnppajmpmnhfheflannaiapmlm', 'dapjbgnjinbpoindlpdmhochffioedbn', 'didkfdopbffjkpolefhpcjkohcpalicd'\n",
    " 'mmeijimgabbpbgpdklnllpncmdofkcpn','pbjikboenpfhbbejgkoklgkhjpfogcam', 'nkbihfbeogaeaoehlefnkodbefgpgknn','obhadkdgdffnnbdfpigjklinjhbkinfh']\n",
    "\n",
    "pp = pd.read_excel('/xxxxxxxx/kmedoids2.xlsx','Sheet2')\n",
    "\n",
    "dump_path='/xxxxxxxx'\n",
    "dump_database_name='plugin.db'\n",
    "\n",
    "\n",
    "db = sqlite3.connect(os.path.join(dump_path, dump_database_name))\n",
    "extkeys = [*extensions.keys()]\n",
    "attri = pd.read_sql(f'SELECT id, rate, rateCount, users, size FROM extensions where privacy != \"not provided\" and privacy != \"None\" and id IN (' + \",\".join([\"?\"] * len(extkeys)) + ')',  params =extkeys, con=db)\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "shapiro = pd.DataFrame()\n",
    "\n",
    "# fully loaded mode\n",
    "for index, row in tqdm(full.iterrows(), total=full.shape[0]):\n",
    "    extid = row.id\n",
    "    base = extensions[extid]['target']+str(index%100//10)\n",
    "    tmp ={\n",
    "        \"cluster\": int(extensions[extid]['label']),# cluster\n",
    "          \"category\":pp[pp.id==extid][\"category\"].values[0],# category\n",
    "          \"pp\":int(extensions[extid]['pp']),\n",
    "          \"location\":int(pp[pp.id==extid][\"Location\"].values[0]),# pp\n",
    "          \"user activity\":int(pp[pp.id==extid][\"User activity\"].values[0]),\n",
    "          \"website content\":int(pp[pp.id==extid][\"Website content\"].values[0]),\n",
    "          \"web history\":int(pp[pp.id==extid][\"Web history\"].values[0]),\n",
    "          \"personally identifiable information\":int(pp[pp.id==extid][\"Personally identifiable information\"].values[0]),\n",
    "          \"authentication information\":int(pp[pp.id==extid][\"Authentication information\"].values[0]),\n",
    "          \"personal communications\":int(pp[pp.id==extid][\"Personal communications\"].values[0]),\n",
    "          \"financial and payment information\":int(pp[pp.id==extid][\"Financial and payment information\"].values[0]),\n",
    "          \"health information\":int(pp[pp.id==extid][\"Health information\"].values[0]),\n",
    "          \"size\":float(attri[attri.id==extid][\"size\"].apply(size_convert).values[0]), # size\n",
    "          \"users\":float(attri[attri.id==extid][\"users\"].apply(user_convert).values[0]), # user #\n",
    "          \"rate\": float(attri[attri.id==extid][\"rate\"]), # star\n",
    "          \"rateCount\": int(attri[attri.id==extid][\"rateCount\"]), # rater #\n",
    "          \"login\": 1 if extid in isLogin else 0, # is login required\n",
    "          \"grant\": 1 if extid in isGrant else 0, # is grant required\n",
    "          \"inactive\": 0, # test based on Generic website, login =1, grant=1\n",
    "          \"fullInactive\": 0, # test based on Generic website, login =0, grant=0\n",
    "          \"testBase\":base, #WebsiteType \n",
    "          \"time\":float(row.time),\n",
    "          \"loading\": float(row.loading),\n",
    "          \"static\": float(row.static)\n",
    "         }\n",
    "    shapiro = pd.concat([shapiro, pd.DataFrame([tmp])], ignore_index=True)\n",
    "# notGrant\n",
    "for index, row in tqdm(notGrant.iterrows(), total=notGrant.shape[0]):\n",
    "    extid = row.id\n",
    "    base = extensions[extid]['target']+str(index%100//10)\n",
    "    tmp ={\n",
    "        \"cluster\": int(extensions[extid]['label']),# cluster\n",
    "          \"category\":pp[pp.id==extid][\"category\"].values[0],# category\n",
    "          \"pp\":int(extensions[extid]['pp']),\n",
    "          \"location\":int(pp[pp.id==extid][\"Location\"].values[0]),# pp\n",
    "          \"user activity\":int(pp[pp.id==extid][\"User activity\"].values[0]),\n",
    "          \"website content\":int(pp[pp.id==extid][\"Website content\"].values[0]),\n",
    "          \"web history\":int(pp[pp.id==extid][\"Web history\"].values[0]),\n",
    "          \"personally identifiable information\":int(pp[pp.id==extid][\"Personally identifiable information\"].values[0]),\n",
    "          \"authentication information\":int(pp[pp.id==extid][\"Authentication information\"].values[0]),\n",
    "          \"personal communications\":int(pp[pp.id==extid][\"Personal communications\"].values[0]),\n",
    "          \"financial and payment information\":int(pp[pp.id==extid][\"Financial and payment information\"].values[0]),\n",
    "          \"health information\":int(pp[pp.id==extid][\"Health information\"].values[0]),\n",
    "          \"size\":float(attri[attri.id==extid][\"size\"].apply(size_convert).values[0]), # size\n",
    "          \"users\":float(attri[attri.id==extid][\"users\"].apply(user_convert).values[0]), # user #\n",
    "          \"rate\": float(attri[attri.id==extid][\"rate\"]), # star\n",
    "          \"rateCount\": int(attri[attri.id==extid][\"rateCount\"]), # rater #\n",
    "          \"login\": 1 if extid in isLogin else 0, # is login required\n",
    "          \"grant\": 0, # is grant required\n",
    "          \"inactive\": 0, # test based on Generic website, login =1, grant=1\n",
    "          \"fullInactive\": 0, # test based on Generic website, login =0, grant=0\n",
    "          \"testBase\":base, #WebsiteType \n",
    "          \"time\":float(row.time),\n",
    "          \"loading\": float(row.loading),\n",
    "          \"static\": float(row.static)\n",
    "         }\n",
    "    shapiro = pd.concat([shapiro, pd.DataFrame([tmp])], ignore_index=True)\n",
    "# notLogin\n",
    "for index, row in tqdm(notLogin.iterrows(), total=notLogin.shape[0]):\n",
    "    extid = row.id\n",
    "    base = extensions[extid]['target']+str(index%100//10)\n",
    "    tmp ={\n",
    "        \"cluster\": int(extensions[extid]['label']),# cluster\n",
    "          \"category\":pp[pp.id==extid][\"category\"].values[0],# category\n",
    "          \"pp\":int(extensions[extid]['pp']),\n",
    "          \"location\":int(pp[pp.id==extid][\"Location\"].values[0]),# pp\n",
    "          \"user activity\":int(pp[pp.id==extid][\"User activity\"].values[0]),\n",
    "          \"website content\":int(pp[pp.id==extid][\"Website content\"].values[0]),\n",
    "          \"web history\":int(pp[pp.id==extid][\"Web history\"].values[0]),\n",
    "          \"personally identifiable information\":int(pp[pp.id==extid][\"Personally identifiable information\"].values[0]),\n",
    "          \"authentication information\":int(pp[pp.id==extid][\"Authentication information\"].values[0]),\n",
    "          \"personal communications\":int(pp[pp.id==extid][\"Personal communications\"].values[0]),\n",
    "          \"financial and payment information\":int(pp[pp.id==extid][\"Financial and payment information\"].values[0]),\n",
    "          \"health information\":int(pp[pp.id==extid][\"Health information\"].values[0]),\n",
    "          \"size\":float(attri[attri.id==extid][\"size\"].apply(size_convert).values[0]), # size\n",
    "          \"users\":float(attri[attri.id==extid][\"users\"].apply(user_convert).values[0]), # user #\n",
    "          \"rate\": float(attri[attri.id==extid][\"rate\"]), # star\n",
    "          \"rateCount\": int(attri[attri.id==extid][\"rateCount\"]), # rater #\n",
    "          \"login\": 0, # is login required\n",
    "          \"grant\": 1 if extid in isGrant else 0, # is grant required\n",
    "          \"inactive\": 0, # test based on Generic website, login =1, grant=1\n",
    "          \"fullInactive\": 0, # test based on Generic website, login =0, grant=0\n",
    "          \"testBase\":base, #WebsiteType \n",
    "          \"time\":float(row.time),\n",
    "          \"loading\": float(row.loading),\n",
    "          \"static\": float(row.static)\n",
    "         }\n",
    "    shapiro = pd.concat([shapiro, pd.DataFrame([tmp])], ignore_index=True)\n",
    "# inactive\n",
    "for index, row in tqdm(inactive.iterrows(), total=inactive.shape[0]):\n",
    "    extid = row.id\n",
    "    base = 'Generic'+str(index%100//10)\n",
    "    tmp ={\n",
    "        \"cluster\": int(extensions[extid]['label']),# cluster\n",
    "          \"category\":pp[pp.id==extid][\"category\"].values[0],# category\n",
    "          \"pp\":int(extensions[extid]['pp']),\n",
    "          \"location\":int(pp[pp.id==extid][\"Location\"].values[0]),# pp\n",
    "          \"user activity\":int(pp[pp.id==extid][\"User activity\"].values[0]),\n",
    "          \"website content\":int(pp[pp.id==extid][\"Website content\"].values[0]),\n",
    "          \"web history\":int(pp[pp.id==extid][\"Web history\"].values[0]),\n",
    "          \"personally identifiable information\":int(pp[pp.id==extid][\"Personally identifiable information\"].values[0]),\n",
    "          \"authentication information\":int(pp[pp.id==extid][\"Authentication information\"].values[0]),\n",
    "          \"personal communications\":int(pp[pp.id==extid][\"Personal communications\"].values[0]),\n",
    "          \"financial and payment information\":int(pp[pp.id==extid][\"Financial and payment information\"].values[0]),\n",
    "          \"health information\":int(pp[pp.id==extid][\"Health information\"].values[0]),\n",
    "          \"size\":float(attri[attri.id==extid][\"size\"].apply(size_convert).values[0]), # size\n",
    "          \"users\":float(attri[attri.id==extid][\"users\"].apply(user_convert).values[0]), # user #\n",
    "          \"rate\": float(attri[attri.id==extid][\"rate\"]), # star\n",
    "          \"rateCount\": int(attri[attri.id==extid][\"rateCount\"]), # rater #\n",
    "          \"login\": 1 if extid in isLogin else 0, # is login required\n",
    "          \"grant\": 1 if extid in isGrant else 0, # is grant required\n",
    "          \"inactive\": 1, # test based on Generic website, login =1, grant=1\n",
    "          \"fullInactive\": 0, # test based on Generic website, login =0, grant=0\n",
    "          \"testBase\":base, #WebsiteType \n",
    "          \"time\":float(row.time),\n",
    "          \"loading\": float(row.loading),\n",
    "          \"static\": float(row.static)\n",
    "         }\n",
    "    shapiro = pd.concat([shapiro, pd.DataFrame([tmp])], ignore_index=True)\n",
    "# fully Inactive\n",
    "for index, row in tqdm(fullinactive.iterrows(), total=fullinactive.shape[0]):\n",
    "    extid = row.id\n",
    "    base = 'Generic'+str(index%100//10)\n",
    "    tmp ={\n",
    "        \"cluster\": int(extensions[extid]['label']),# cluster\n",
    "          \"category\":pp[pp.id==extid][\"category\"].values[0],# category\n",
    "          \"pp\":int(extensions[extid]['pp']),\n",
    "          \"location\":int(pp[pp.id==extid][\"Location\"].values[0]),# pp\n",
    "          \"user activity\":int(pp[pp.id==extid][\"User activity\"].values[0]),\n",
    "          \"website content\":int(pp[pp.id==extid][\"Website content\"].values[0]),\n",
    "          \"web history\":int(pp[pp.id==extid][\"Web history\"].values[0]),\n",
    "          \"personally identifiable information\":int(pp[pp.id==extid][\"Personally identifiable information\"].values[0]),\n",
    "          \"authentication information\":int(pp[pp.id==extid][\"Authentication information\"].values[0]),\n",
    "          \"personal communications\":int(pp[pp.id==extid][\"Personal communications\"].values[0]),\n",
    "          \"financial and payment information\":int(pp[pp.id==extid][\"Financial and payment information\"].values[0]),\n",
    "          \"health information\":int(pp[pp.id==extid][\"Health information\"].values[0]),\n",
    "          \"size\":float(attri[attri.id==extid][\"size\"].apply(size_convert).values[0]), # size\n",
    "          \"users\":float(attri[attri.id==extid][\"users\"].apply(user_convert).values[0]), # user #\n",
    "          \"rate\": float(attri[attri.id==extid][\"rate\"]), # star\n",
    "          \"rateCount\": int(attri[attri.id==extid][\"rateCount\"]), # rater #\n",
    "          \"login\": 0, # is login required\n",
    "          \"grant\": 0, # is grant required\n",
    "          \"inactive\": 0, # test based on Generic website, login =1, grant=1\n",
    "          \"fullInactive\": 1, # test based on Generic website, login =0, grant=0\n",
    "          \"testBase\":base, #WebsiteType \n",
    "          \"time\":float(row.time),\n",
    "          \"loading\": float(row.loading),\n",
    "          \"static\": float(row.static)\n",
    "         }\n",
    "    shapiro = pd.concat([shapiro, pd.DataFrame([tmp])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec08360",
   "metadata": {},
   "outputs": [],
   "source": [
    "test =  shapiro.copy()\n",
    "\n",
    "test.drop(['financial and payment information', 'health information'], axis=1, inplace=True)\n",
    "\n",
    "one_hot2 = pd.get_dummies(test.testBase, prefix='base')\n",
    "test.drop('category',axis = 1, inplace = True)\n",
    "test.drop('testBase',axis = 1, inplace = True)\n",
    "test.rename({'testBase': 'base'}, axis=1, inplace=True)\n",
    "test = test.join(one_hot2)\n",
    "test\n",
    "from pyexcelerate import Workbook\n",
    "\n",
    "save = [test.columns.tolist(), ] + test.values.tolist()\n",
    "wb = Workbook()\n",
    "wb.new_sheet('sheet1', data=save)\n",
    "wb.save('/xxxxxxxx/shapiro.xlsx')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
