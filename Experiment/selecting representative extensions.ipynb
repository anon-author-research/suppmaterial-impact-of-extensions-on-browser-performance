{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c686daf5-cf24-48f9-b454-6ad0659ead1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008cba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_path='/Users/xxxxx'\n",
    "dump_database_name='plugin.db'\n",
    "\n",
    "\n",
    "db = sqlite3.connect(os.path.join(dump_path, dump_database_name))\n",
    "c = db.cursor()\n",
    "\n",
    "pd.read_sql(f'SELECT category,count(id) FROM extensions group by category', con=db)\n",
    "# total\n",
    "len(pd.read_sql(f'SELECT id FROM extensions', con=db))\n",
    "# with privacy practices\n",
    "len(pd.read_sql(f'SELECT id, name, category, rate, rateCount, users, privacy, size FROM extensions where privacy != \"not provided\" and privacy != \"None\"', con=db))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f59a857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import f\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "# some collected extensions after few days or hours may be no longer available anymore\n",
    "\n",
    "pool = Pool(10)\n",
    "vaild_id = pd.read_sql(f'SELECT id FROM extensions', con=db)['id'].to_list()\n",
    "invaild_id = []\n",
    "jobs = []\n",
    "\n",
    "with Pool(processes=10) as p:\n",
    "    with tqdm(vaild_id) as pbar:\n",
    "        for _ in p.imap_unordered(f.f, vaild_id):\n",
    "            pbar.update()\n",
    "            if _ is not None:\n",
    "                invaild_id.append(_)\n",
    "\n",
    "# second times try\n",
    "invaild_id2 = []\n",
    "with Pool(processes=10) as p:\n",
    "    with tqdm(invaild_id) as pbar:\n",
    "        for _ in p.imap_unordered(f.f, invaild_id):\n",
    "            pbar.update()\n",
    "            if _ is not None:\n",
    "                invaild_id2.append(_)\n",
    "                \n",
    "print(len(invaild_id2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17a3957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "def write_excel(filename,sheetname,dataframe):\n",
    "    book = load_workbook(filename)\n",
    "    writer = pd.ExcelWriter(filename, engine='openpyxl') \n",
    "    writer.book = book\n",
    "\n",
    "    writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "    dataframe.to_excel(writer, sheetname,index=False)\n",
    "\n",
    "    writer.save()\n",
    "\n",
    "# conver the collected number of users to integer\n",
    "def user_convert(u):\n",
    "    if '+' in u:\n",
    "        return int(float(u.split('+')[0].strip().replace(',','')))\n",
    "    else: return int(float(u.split(' ')[0].strip().replace(',','')))\n",
    "# conver the collected extension size to integer\n",
    "def size_convert(s):\n",
    "    scaler = {'KiB': 1,'MiB': 1024}\n",
    "    s = re.split('([-+]?\\d+\\.\\d+)|([-+]?\\d+)',s.strip())\n",
    "    s = [r.strip() for r in s if r is not None and r.strip() != '']\n",
    "    return float(s[0])*scaler[s[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fc4d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert properties in privacy practices to 9-dimensional vectors\n",
    "rows = pd.read_sql(f'SELECT id, name, category, rate, rateCount, users, privacy, size FROM extensions where privacy != \"not provided\" and privacy != \"None\" and id not in {tuple(invaild_id2)}', con=db)\n",
    "rows['users'] = rows['users'].apply(user_convert)\n",
    "rows['size']=rows['size'].apply(size_convert)\n",
    "for i in rows.index:\n",
    "    for pp in rows.at[i, \"privacy\"].split(';'):\n",
    "        rows.at[i, f\"{pp}\"] = 1\n",
    "\n",
    "rows = rows.fillna(0)\n",
    "\n",
    "dt =rows.copy()\n",
    "dt.drop(['id'], axis=1, inplace=True)\n",
    "dt.drop(['name'], axis=1, inplace=True)\n",
    "dt.drop(['category'], axis=1, inplace=True)\n",
    "dt.drop(['privacy'], axis=1, inplace=True)\n",
    "dt.drop(['rate'], axis=1, inplace=True)\n",
    "dt.drop(['rateCount'], axis=1, inplace=True)\n",
    "dt.drop(['users'], axis=1, inplace=True)\n",
    "dt.drop(['size'], axis=1, inplace=True)\n",
    "\n",
    "smart_array = dt.copy().values\n",
    "smart_array[:,0] = smart_array[:,0].astype(str)\n",
    "categorical_index = list([0])\n",
    "\n",
    "c.close()\n",
    "db.close()\n",
    "print(categorical_index)\n",
    "print(len(smart_array))\n",
    "print(smart_array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681d2e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the optimal K value\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from sklearn.cluster import KMeans\n",
    "model = KMeans()\n",
    "\n",
    "visualizer1 = KElbowVisualizer(model, k=(2,12), n_jobs = -1) #metric='distortion'\n",
    "visualizer2 = KElbowVisualizer(model, k=(2,12),metric='silhouette', n_jobs = -1) #metric='silhouette'\n",
    "\n",
    "# check both for the best K\n",
    "visualizer1.fit(smart_array)        # Fit the data to the visualizer\n",
    "visualizer1.show()  \n",
    "\n",
    "visualizer2.fit(smart_array)        # Fit the data to the visualizer\n",
    "visualizer2.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9e852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kmedoids\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "euc = euclidean_distances(smart_array)\n",
    "# check the loss\n",
    "\n",
    "# fp = kmedoids.fasterpam(euc,5)\n",
    "# print('FasterPAM Loss:', fp.loss)\n",
    "\n",
    "fp1 = kmedoids.fastpam1(euc,5) # 5 is my optimal K value -choose yours\n",
    "print('Fast PAM Loss:', fp1.loss)\n",
    "\n",
    "# pam = kmedoids.pam(euc,5)\n",
    "# print('pam Loss:', pam.loss)\n",
    "\n",
    "# alt = kmedoids.alternating(euc,5)\n",
    "# print('Alternating Loss:', alt.loss)\n",
    "\n",
    "# to see the medoids of the clusters\n",
    "print(sorted(fp1.medoids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52978912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the clustering results to excel\n",
    "dfpam = rows.copy()\n",
    "\n",
    "dfpam['labels'] = fp1.labels\n",
    "dfpam.drop(['id'], axis=1, inplace=True)\n",
    "dfpam.drop(['name'], axis=1, inplace=True)\n",
    "dfpam.drop(['category'], axis=1, inplace=True)\n",
    "dfpam.drop(['privacy'], axis=1, inplace=True)\n",
    "dfpam.drop(['rate'], axis=1, inplace=True)\n",
    "dfpam.drop(['rateCount'], axis=1, inplace=True)\n",
    "dfpam.drop(['users'], axis=1, inplace=True)\n",
    "\n",
    "dfpam.drop(['size'], axis=1, inplace=True)\n",
    "\n",
    "first_column = dfpam.pop('labels')\n",
    "dfpam.insert(0, 'labels', first_column)\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "tmp = dfpam.groupby(dfpam.columns.tolist(),as_index=False).size()\n",
    "# tmp = tmp.groupby(['labels','category']).apply(lambda x: x.sample(frac=1)).drop(['category'], axis=1).drop(['labels'], axis=1)\n",
    "tmp = tmp.groupby(['labels','category']).apply(lambda x: x.sample(frac=1))\n",
    "tmp.to_excel('./kmedoids2.xlsx',index=False,sheet_name='Sheet1')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573709d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances,manhattan_distances\n",
    "import requests\n",
    "\n",
    "# find extension with the min distance to the medoid\n",
    "def idxByMinVal(data, subclu, ana):\n",
    "    dist = [sum(x) for x in data]\n",
    "    idxs = np.argwhere(dist == np.amin(dist))\n",
    "    minIdx = {'idx':-1,'users':-1,'rate':-1.0,'rateCount':-1}\n",
    "    \n",
    "    # if the distance of extensions is same, we follow the order \n",
    "    # to ckeck # of user, rating score, and then # of raters\n",
    "    for indx in idxs:\n",
    "        if minIdx['users'] == subclu.iloc[indx[0]]['users']:\n",
    "            if minIdx['rate'] == subclu.iloc[indx[0]]['rate']:\n",
    "                if minIdx['rateCount'] == subclu.iloc[indx[0]]['rateCount']:\n",
    "                    minIdx['idx'] = indx[0]\n",
    "                    minIdx['users'] = subclu.iloc[indx[0]]['users']\n",
    "                    minIdx['rate'] = subclu.iloc[indx[0]]['rate']\n",
    "                    minIdx['rateCount'] = subclu.iloc[indx[0]]['rateCount']\n",
    "                    \n",
    "            elif minIdx['rate'] < subclu.iloc[indx[0]]['rate']:\n",
    "                minIdx['idx'] = indx[0]\n",
    "                minIdx['users'] = subclu.iloc[indx[0]]['users']\n",
    "                minIdx['rate'] = subclu.iloc[indx[0]]['rate']\n",
    "                minIdx['rateCount'] = subclu.iloc[indx[0]]['rateCount']\n",
    "                \n",
    "        elif minIdx['users'] < subclu.iloc[indx[0]]['users']:\n",
    "            minIdx['idx'] = indx[0]\n",
    "            minIdx['users'] = subclu.iloc[indx[0]]['users']\n",
    "            minIdx['rate'] = subclu.iloc[indx[0]]['rate']\n",
    "            minIdx['rateCount'] = subclu.iloc[indx[0]]['rateCount']\n",
    "    return minIdx['idx']\n",
    "\n",
    "def get_col_name(datarow): \n",
    "    return datarow.columns[datarow.eq(1).any()].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc93e8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "extension = pd.DataFrame(columns=['labels','category','id','name','pp'])\n",
    "b = pd.read_excel('./kmedoids2.xlsx','Sheet2')\n",
    "\n",
    "for label in b['labels'].drop_duplicates().values:\n",
    "    for cate in b.loc[b['labels']==label]['category'].drop_duplicates().values:\n",
    "        sublbl = b.loc[b['labels']==label]\n",
    "        subclu =  sublbl.loc[sublbl['category']==cate]\n",
    "        \n",
    "        idx = idxByMinVal(manhattan_distances(subclu.iloc[:,7:16].values),subclu,[label,cate])\n",
    "        minSubRow = subclu.iloc[idx]\n",
    "        \n",
    "        rowId =minSubRow['id']\n",
    "        if requests.get(f'https://chrome.google.com/webstore/detail/chegg-answers-free/{rowId}?hl=ca').status_code==200:\n",
    "            subclu = subclu[subclu['id']!=rowId]\n",
    "            \n",
    "        val = pd.DataFrame({'labels':label,'category':cate,'id':minSubRow['id'],'name':minSubRow['name'],'pp':minSubRow[7:16].sum()}, index=[0])\n",
    "        extension = pd.concat([extension, val], ignore_index=True, axis = 0)\n",
    "        \n",
    "extension.groupby(extension.columns.tolist(),as_index=False).size().drop(['size'], axis=1, inplace=True)\n",
    "extension.groupby(['labels','pp']).apply(lambda x: x.sample(frac=1)).drop(['pp'], axis=1).drop(['labels'], axis=1)\n",
    "\n",
    "# extension\n",
    "write_excel('./kmedoids2.xlsx','extensions',extension)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745c1558",
   "metadata": {},
   "outputs": [],
   "source": [
    "extension = pd.read_excel('./kmedoids2.xlsx',sheet_name='extensions')\n",
    "# see the use of the privacy practices in each cluster\n",
    "for label in extension['labels'].drop_duplicates().values:\n",
    "    for lid in extension.loc[extension['labels']==label]['id']:\n",
    "        print(label, extension.loc[extension['id']==lid]['pp'],get_col_name(b[b['id']==lid].iloc[:,7:16]))\n",
    "    print('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40cb0b77",
   "metadata": {},
   "source": [
    "# Select the next consecutive extension with the min distance to the medoid if the selected extension is not capable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1487a6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "replaceId=['pgpidfocdapogajplhjofamgeboonmmj']\n",
    "\n",
    "def idxByMinValExcept(data,replaceId):\n",
    "    # print(data)\n",
    "    # print([sum(x) for x in data])\n",
    "    pp = manhattan_distances(data.iloc[:,7:16].values)\n",
    "    dist = [sum(x) for x in pp]\n",
    "    idxs = np.argwhere(dist == np.amin(dist))\n",
    "    \n",
    "    subclu = data\n",
    "    minIdx = {'idx':-1,'users':-1,'rate':-1.0,'rateCount':-1}\n",
    "    \n",
    "    for indx in idxs:\n",
    "       \n",
    "        rowId = subclu.iloc[indx[0]]['id']\n",
    "        if rowId not in invaild_id2 and rowId not in replaceId:\n",
    "            if minIdx['users'] == subclu.iloc[indx[0]]['users']:\n",
    "                if minIdx['rate'] == subclu.iloc[indx[0]]['rate']:\n",
    "                    if minIdx['rateCount'] == subclu.iloc[indx[0]]['rateCount']:\n",
    "                        minIdx['idx'] = indx[0]\n",
    "                        minIdx['users'] = subclu.iloc[indx[0]]['users']\n",
    "                        minIdx['rate'] = subclu.iloc[indx[0]]['rate']\n",
    "                        minIdx['rateCount'] = subclu.iloc[indx[0]]['rateCount']\n",
    "\n",
    "                elif minIdx['rate'] < subclu.iloc[indx[0]]['rate']:\n",
    "                    minIdx['idx'] = indx[0]\n",
    "                    minIdx['users'] = subclu.iloc[indx[0]]['users']\n",
    "                    minIdx['rate'] = subclu.iloc[indx[0]]['rate']\n",
    "                    minIdx['rateCount'] = subclu.iloc[indx[0]]['rateCount']\n",
    "\n",
    "            elif minIdx['users'] < subclu.iloc[indx[0]]['users']:\n",
    "                minIdx['idx'] = indx[0]\n",
    "                minIdx['users'] = subclu.iloc[indx[0]]['users']\n",
    "                minIdx['rate'] = subclu.iloc[indx[0]]['rate']\n",
    "                minIdx['rateCount'] = subclu.iloc[indx[0]]['rateCount']\n",
    "    return minIdx['idx']\n",
    "\n",
    "extension = pd.DataFrame(columns=['labels','category','id','name','# pp'])\n",
    "\n",
    "for label in b['labels'].drop_duplicates().values:\n",
    "    for cate in b.loc[b['labels']==label]['category'].drop_duplicates().values:\n",
    "        sublbl = b.loc[b['labels']==label]\n",
    "        subclu =  sublbl.loc[sublbl['category']==cate]\n",
    "        \n",
    "        idx = idxByMinValExcept(subclu,replaceId)\n",
    "        minSubRow = subclu.iloc[idx]\n",
    "        val = pd.DataFrame({'labels':label,'category':cate,'id':minSubRow['id'],'name':minSubRow['name'],'# pp':minSubRow[7:16].sum()}, index=[0])\n",
    "        extension = pd.concat([extension, val], ignore_index=True, axis = 0)\n",
    "\n",
    "extension.groupby(extension.columns.tolist(),as_index=False).size().drop(['size'], axis=1, inplace=True)\n",
    "extension.groupby(['labels','category','# pp']).apply(lambda x: x.sample(frac=1)).drop(['# pp'], axis=1).drop(['labels'], axis=1)\n",
    "\n",
    "# write_excel('./kmedoids2.xlsx','replace',extension)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:48:25) \n[Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "ed131af3fd417b2b9a61d0852e013cc19c9b4cd4bf5c8d854616e3a15a9b0975"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
